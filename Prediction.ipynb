{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing Libraries***"
      ],
      "metadata": {
        "id": "9RXuinX1-KLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQPjq9uaI9eH",
        "outputId": "93afe256-1473-4e58-900d-0d14f226a480"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "2KNYwpR480CO"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from textblob import TextBlob\n",
        "import spacy , contractions\n",
        "import nltk , re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from datetime import datetime\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization , LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Loading Prediction Data Set***"
      ],
      "metadata": {
        "id": "6yU9yXMn-SWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/PredictionData.xlsx')"
      ],
      "metadata": {
        "id": "w01U0GIx-C-U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = ['Unnamed: 0.1' , 'Unnamed: 0' , 'num_words_in_transcript'] , inplace = True)"
      ],
      "metadata": {
        "id": "BjeuZEYU-DKt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXsoj-5J-DN3",
        "outputId": "3d2683ef-afd6-4aef-c2e8-b2f2be25fc5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   ID                   100 non-null    object\n",
            " 1   Name                 100 non-null    object\n",
            " 2   Role                 100 non-null    object\n",
            " 3   Transcript           100 non-null    object\n",
            " 4   Resume               100 non-null    object\n",
            " 5   Reason for decision  100 non-null    object\n",
            " 6   Job Description      100 non-null    object\n",
            "dtypes: object(7)\n",
            "memory usage: 5.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Pre processing Data***"
      ],
      "metadata": {
        "id": "xPZT5EEh_I6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9my-ZD9BWaU",
        "outputId": "259ed26f-431f-47d6-c3a3-0054ed46349a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessing:\n",
        "\n",
        "  def __init__(self , data):\n",
        "    self.data = data\n",
        "    print('Initiating the Pre processing \\n')\n",
        "    self.textProcessing()\n",
        "\n",
        "  def textProcessing(self):\n",
        "\n",
        "    print('Step 1/8 ==> Started ............')\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    stopword_s = stopwords.words('english')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def pre_process(text):\n",
        "      text = contractions.fix(text) # expanding the contractions like , I'm with I am and it's with It is and so on...\n",
        "      text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_`{|}~]', '', text)  # Removing all these characters from the text\n",
        "      sentences = re.split(r'(?<=[.!?])\\s+', text)   # Splitting the text as sentences using the regular expressions\n",
        "      for idx, sent in enumerate(sentences):\n",
        "          words = nlp(sent)  # converting the sentence into words\n",
        "          words = [word.text for word in words if word.text.lower() not in stopword_s] # Removing the stopwords from the text\n",
        "          words = [lemmatizer.lemmatize(word) for word in words]  # Using the Lemmatization techniques\n",
        "          sentences[idx] = ' '.join(words)  # Replacing the original sentence with the new sentence\n",
        "      return ' '.join(sentences)  # Join the sentences back together\n",
        "\n",
        "    self.data['Resume_processed'] = self.data['Resume'].apply(pre_process)\n",
        "    self.data['Job_Description_processed'] = self.data['Job Description'].apply(pre_process)\n",
        "    self.data['Transcript_processed'] = self.data['Transcript'].apply(pre_process)\n",
        "\n",
        "    print('Step 1/8 ==> Pre processing of texts in the dataset executed Successfully \\n')\n",
        "\n",
        "    self.analyze_sentiment()\n",
        "\n",
        "  def analyze_sentiment(self):\n",
        "\n",
        "    print('Step 2/8 ==> Started ............')\n",
        "\n",
        "    def sentiment(text):\n",
        "      # Create a TextBlob object\n",
        "      blob = TextBlob(text)\n",
        "\n",
        "      # Get the sentiment polarity\n",
        "      polarity = blob.sentiment.polarity\n",
        "\n",
        "      return polarity\n",
        "\n",
        "    self.data['Transcript_sentiment'] = self.data['Transcript_processed'].apply(sentiment)\n",
        "    self.data['Resume_sentiment'] = self.data['Resume_processed'].apply(sentiment)\n",
        "    self.data['JobDescription_sentiment'] = self.data['Job_Description_processed'].apply(sentiment)\n",
        "\n",
        "    print('Step 2/8 ==> Sentiment Calculation of Each colum Excuted Succesfully \\n')\n",
        "\n",
        "    self.word_counts()\n",
        "\n",
        "  def word_counts(self):\n",
        "\n",
        "    print('Step 3/8 ==> Started ............')\n",
        "\n",
        "    def counts(text):\n",
        "      return len(text.split())\n",
        "\n",
        "    self.data['Transcript_words'] = self.data['Transcript_processed'].apply(counts)\n",
        "    self.data['Resume_words'] = self.data['Resume_processed'].apply(counts)\n",
        "\n",
        "    print('Step 3/8 ==> Extracting Word Counts Excuted Succesfully \\n')\n",
        "\n",
        "    self.extract_years_of_experience()\n",
        "\n",
        "  def extract_years_of_experience(self):\n",
        "\n",
        "      print('Step 4/8 ==> Started ............')\n",
        "\n",
        "      def years_of_experience(text):\n",
        "          # Regular expression to extract years and date ranges\n",
        "          date_ranges = re.findall(r\"(\\d{4})-(present|\\d{4})\", text.lower())\n",
        "\n",
        "          total_years = 0\n",
        "          current_year = datetime.now().year\n",
        "\n",
        "          for start, end in date_ranges:\n",
        "              start_year = int(start)\n",
        "              end_year = current_year if end == \"present\" else int(end)\n",
        "\n",
        "              total_years += (end_year - start_year)\n",
        "\n",
        "          return total_years\n",
        "      self.data['Years_Experience']=self.data['Resume'].apply(years_of_experience)\n",
        "\n",
        "      print('Step 4/8 ==> Extracting Years of Experience Excuted Succesfully \\n')\n",
        "      self.process_dataset()\n",
        "\n",
        "\n",
        "  def extract_resume_features(self,resume_text, jd_text):\n",
        "    features = {}\n",
        "\n",
        "    # Length-based features\n",
        "    features['resume_sentence_count'] = len(sent_tokenize(resume_text))\n",
        "    features['resume_avg_word_length'] = sum(len(word) for word in word_tokenize(resume_text)) / len(word_tokenize(resume_text))\n",
        "\n",
        "    # Skill match features\n",
        "    jd_skills = set(re.findall(r'\\b[A-Za-z]+\\b', jd_text.lower()))\n",
        "    resume_skills = set(re.findall(r'\\b[A-Za-z]+\\b', resume_text.lower()))\n",
        "    features['skill_match_count'] = len(jd_skills & resume_skills)\n",
        "\n",
        "    # Education features\n",
        "    degrees = ['b.tech', 'm.tech', 'mba', 'phd', 'bachelor', 'master']\n",
        "    features['university_education_count'] = sum(1 for degree in degrees if degree in resume_text.lower())\n",
        "\n",
        "    return features\n",
        "\n",
        "  def process_dataset(self):\n",
        "\n",
        "    print('Step 5/8 ==> Started ............')\n",
        "\n",
        "    def process_dataset_resume_features(data, resume_col, jd_col):\n",
        "        \"\"\"\n",
        "        Process a dataset to extract features for each resume-JD pair.\n",
        "\n",
        "        Parameters:\n",
        "        - data (pd.DataFrame): Dataset containing resumes and job descriptions.\n",
        "        - resume_col (str): Column name for resumes.\n",
        "        - jd_col (str): Column name for job descriptions.\n",
        "\n",
        "        Returns:\n",
        "        - pd.DataFrame: Original dataset with extracted features appended.\n",
        "        \"\"\"\n",
        "        extracted_features = []\n",
        "\n",
        "        for _, row in data.iterrows():\n",
        "            resume_text = row[resume_col]\n",
        "            jd_text = row[jd_col]\n",
        "            features = self.extract_resume_features(resume_text, jd_text)\n",
        "            extracted_features.append(features)\n",
        "\n",
        "        # Combine features into a DataFrame\n",
        "        features_df = pd.DataFrame(extracted_features)\n",
        "        return pd.concat([data, features_df], axis=1)\n",
        "\n",
        "    # Process the dataset\n",
        "    self.processed_data = process_dataset_resume_features(self.data, \"Resume_processed\", \"Job_Description_processed\")\n",
        "\n",
        "    print('Step 5/8 ==> Extracting Resume Features Excuted Succesfully \\n')\n",
        "\n",
        "    self.process_transcript()\n",
        "\n",
        "  def extract_transcript_features(self,transcript_text):\n",
        "\n",
        "    features = {}\n",
        "    # Language features\n",
        "    features['transcript_vocab_diversity'] = len(set(word_tokenize(transcript_text))) / len(word_tokenize(transcript_text))\n",
        "    features['transcript_avg_sentence_length'] = sum(len(sent.split()) for sent in sent_tokenize(transcript_text)) / len(sent_tokenize(transcript_text))\n",
        "    return features\n",
        "\n",
        "  def process_transcript(self):\n",
        "\n",
        "    print('Step 6/8 ==> Started ............')\n",
        "    def process_transcript(data, transcript_col = 'Transcript_processed'):\n",
        "      extracted_features = []\n",
        "\n",
        "      for _, row in data.iterrows():\n",
        "          transcript_text = row[transcript_col]\n",
        "          features = self.extract_transcript_features(transcript_text)\n",
        "          extracted_features.append(features)\n",
        "\n",
        "      # Combine features into a DataFrame\n",
        "      features_df = pd.DataFrame(extracted_features)\n",
        "      return pd.concat([data, features_df], axis=1)\n",
        "\n",
        "     # Process the dataset\n",
        "    self.processed_data = process_transcript(self.processed_data)\n",
        "\n",
        "    print('Step 6/8 ==> Extracting Transcript Features Excuted Succesfully \\n')\n",
        "\n",
        "    self.tfidfSimilarityCalculator()\n",
        "\n",
        "  def tfidfSimilarityCalculator(self):\n",
        "\n",
        "    print('Step 7/8 ==> Started ............')\n",
        "\n",
        "    # Loading the fitted Tf-Idf-Vectorizer Models\n",
        "\n",
        "    resume_Jd_filename = \"/content/sim_of_Resume_processed_and_Job_Description_processed.joblib\"\n",
        "    resume_Transcript_filename = \"/content/sim_of_Resume_processed_and_Transcript_processed.joblib\"\n",
        "    Transcript_JD_filename = \"/content/sim_of_Transcript_processed_and_Job_Description_processed.joblib\"\n",
        "\n",
        "    resume_Jd_vectorizer = joblib.load(resume_Jd_filename)\n",
        "    resume_Transcript_vectorizer = joblib.load(resume_Transcript_filename)\n",
        "    Transcript_JD_vectorizer = joblib.load(Transcript_JD_filename)\n",
        "\n",
        "    #  Transform new text data\n",
        "    def similarity_calculator(vectorizer , col1 , col2):\n",
        "\n",
        "      col1_vector = resume_Jd_vectorizer.transform(self.data[col1]).toarray()\n",
        "      col2_vector = resume_Jd_vectorizer.transform(self.data[col2]).toarray()\n",
        "\n",
        "      similarities = [\n",
        "          cosine_similarity(col1_vector[i].reshape(1, -1), col2_vector[i].reshape(1, -1))[0][0]\n",
        "          for i in range(len(col1_vector))]\n",
        "      return similarities\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    self.processed_data['Resume_Jd_similarity'] = similarity_calculator(resume_Jd_vectorizer , 'Resume_processed' , 'Job_Description_processed')\n",
        "    self.processed_data['Resume_Transcript_similarity'] = similarity_calculator(resume_Transcript_vectorizer , 'Resume_processed' , 'Transcript_processed')\n",
        "    self.processed_data['Transcript_Jd_similarity'] = similarity_calculator(Transcript_JD_vectorizer , 'Transcript_processed' , 'Job_Description_processed')\n",
        "\n",
        "    print('Step 7/8 ==> Similarity Calculation Excuted Succesfully \\n')\n",
        "\n",
        "    self.bertEmbeddings()\n",
        "\n",
        "\n",
        "  def bertEmbeddings(self):\n",
        "\n",
        "    print('Step 8/8 ==> Started ............')\n",
        "\n",
        "    transcripts = self.processed_data['Transcript'].tolist()\n",
        "    resumes = self.processed_data['Resume'].tolist()\n",
        "    job_desc = self.processed_data['Job Description'].tolist()\n",
        "\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    def get_bert_embeddings_batch(texts, tokenizer, model, batch_size=32):\n",
        "      embeddings = []\n",
        "      total_batches = (len(texts) + batch_size - 1) // batch_size  # Total number of batches\n",
        "      for i in range(total_batches):\n",
        "          # Get the current batch\\n\",\n",
        "          batch = texts[i * batch_size:(i + 1) * batch_size]\n",
        "          inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "          with torch.no_grad():\n",
        "              outputs = model(**inputs)\n",
        "          # Use the [CLS] token representation for each text in the batch\\n\",\n",
        "          batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy(),\n",
        "          embeddings.extend(batch_embeddings)\n",
        "      return embeddings\n",
        "\n",
        "    tra_emb = get_bert_embeddings_batch(transcripts, tokenizer, model, batch_size=32)\n",
        "    flat_embeddings_tra = [embedding for batch in tra_emb for embedding in batch]\n",
        "    self.processed_data['Transcript_bert'] = flat_embeddings_tra\n",
        "\n",
        "    res_emb = get_bert_embeddings_batch(resumes, tokenizer, model, batch_size=32)\n",
        "    flat_embeddings_res = [embedding for batch in res_emb for embedding in batch]\n",
        "    self.processed_data['Resume_bert'] = flat_embeddings_res\n",
        "\n",
        "    jd_emb = get_bert_embeddings_batch(job_desc, tokenizer, model, batch_size=32)\n",
        "    flat_embeddings_jd = [embedding for batch in jd_emb for embedding in batch]\n",
        "    self.processed_data['Jd_bert'] = flat_embeddings_jd\n",
        "\n",
        "    trans_expanded = pd.DataFrame(self.processed_data['Transcript_bert'].tolist(), index=self.processed_data.index)\n",
        "    trans_expanded.columns = [f'trans_emb_{i}' for i in range(trans_expanded.shape[1])]\n",
        "\n",
        "    res_expanded = pd.DataFrame(self.processed_data['Resume_bert'].tolist(), index=self.processed_data.index)\n",
        "    res_expanded.columns = [f'resume_emb_{i}' for i in range(res_expanded.shape[1])]\n",
        "\n",
        "    jd_expanded = pd.DataFrame(self.processed_data['Jd_bert'].tolist(), index=self.processed_data.index)\n",
        "    jd_expanded.columns = [f'jd_emb_{i}' for i in range(jd_expanded.shape[1])]\n",
        "\n",
        "    self.processed_data = pd.concat([self.processed_data, trans_expanded, res_expanded , jd_expanded], axis=1)\n",
        "\n",
        "    simi_res_tra = []\n",
        "    simi_res_jd = []\n",
        "    simi_tra_jd = []\n",
        "\n",
        "    for tra , res in zip(flat_embeddings_tra , flat_embeddings_res):\n",
        "      simi_res_tra.append(cosine_similarity([tra],[res])[0][0])\n",
        "\n",
        "    for jd , res in zip(flat_embeddings_jd , flat_embeddings_res):\n",
        "      simi_res_jd.append(cosine_similarity([jd],[res])[0][0])\n",
        "\n",
        "    for tra , jd in zip(flat_embeddings_tra , flat_embeddings_jd):\n",
        "      simi_tra_jd.append(cosine_similarity([tra],[jd])[0][0])\n",
        "\n",
        "    self.processed_data['Bert_TransRes_Similarity']     = simi_res_tra\n",
        "    self.processed_data['Bert_ResJobDesc_Similarity']   = simi_res_jd\n",
        "    self.processed_data['Bert_TransJobDesc_Similarity'] = simi_tra_jd\n",
        "\n",
        "    self.processed_data.drop(columns=['Transcript_bert', 'Resume_bert','Jd_bert'], inplace = True)\n",
        "\n",
        "    print('Step 8/8 ==> BERT Embeddings Excuted Succesfully \\n')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oNyq4dw0_Bdd"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df.copy()\n",
        "pre_processing = Preprocessing(df_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFFwfGOk_Baa",
        "outputId": "b4ccaf2e-c024-4cf6-e3ce-4fb74eecc51f"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating the Pre processing \n",
            "\n",
            "Step 1/8 ==> Started ............\n",
            "Step 1/8 ==> Pre processing of texts in the dataset executed Successfully \n",
            "\n",
            "Step 2/8 ==> Started ............\n",
            "Step 2/8 ==> Sentiment Calculation of Each colum Excuted Succesfully \n",
            "\n",
            "Step 3/8 ==> Started ............\n",
            "Step 3/8 ==> Extracting Word Counts Excuted Succesfully \n",
            "\n",
            "Step 4/8 ==> Started ............\n",
            "Step 4/8 ==> Extracting Years of Experience Excuted Succesfully \n",
            "\n",
            "Step 5/8 ==> Started ............\n",
            "Step 5/8 ==> Extracting Resume Features Excuted Succesfully \n",
            "\n",
            "Step 6/8 ==> Started ............\n",
            "Step 6/8 ==> Extracting Transcript Features Excuted Succesfully \n",
            "\n",
            "Step 7/8 ==> Started ............\n",
            "Step 7/8 ==> Similarity Calculation Excuted Succesfully \n",
            "\n",
            "Step 8/8 ==> Started ............\n",
            "Step 8/8 ==> BERT Embeddings Excuted Succesfully \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_processed_data = pre_processing.processed_data"
      ],
      "metadata": {
        "id": "UjSAhnKA_BUA"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_file = '/content/xgb_bert.joblib'\n",
        "nn_file = '/content/ann_model.h5'\n",
        "\n",
        "xgb_model = joblib.load(xgb_file)"
      ],
      "metadata": {
        "id": "Dwan98gJ-DQ2"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "ann_model = load_model(nn_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kVsiUE2ev7U",
        "outputId": "c3a88949-4d86-443d-9f5f-5ba89d262020"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Predictions***\n",
        "\n",
        "Best performining model is the ensemble model of average probability of XGBoost and NeuralNetwork"
      ],
      "metadata": {
        "id": "RVaeUmGqsx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_preds(model , data):\n",
        "  preds = model.predict_proba(data)[:, 1]\n",
        "  return preds"
      ],
      "metadata": {
        "id": "tt388wpxev-L"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ann_preds(model , data):\n",
        "  preds = model.predict(data)\n",
        "  preds = [i[0] for i in preds]\n",
        "  return preds"
      ],
      "metadata": {
        "id": "rQBeB55-ewBO"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns that are used in the XGB model and ANN model"
      ],
      "metadata": {
        "id": "7AOYc2rMzVbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "derived_features = pre_processed_data[['Transcript_sentiment','Resume_sentiment', 'JobDescription_sentiment', 'Transcript_words',\n",
        "       'Resume_words', 'Years_Experience', 'resume_avg_word_length', 'skill_match_count','university_education_count', 'transcript_vocab_diversity',\n",
        "       'transcript_avg_sentence_length' , 'Bert_TransRes_Similarity', 'Bert_TransJobDesc_Similarity' , 'Bert_ResJobDesc_Similarity']]"
      ],
      "metadata": {
        "id": "RMVqD5LCewEC"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_columns = [col for col in pre_processed_data.columns if col.startswith('trans_emb_') or col.startswith('resume_emb_') or col.startswith('jd_emb_')]\n",
        "X = pre_processed_data[embedding_columns]"
      ],
      "metadata": {
        "id": "NcnM0ly8ewHK"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.concat([X,derived_features],axis=1)"
      ],
      "metadata": {
        "id": "KrUNJZ8oewJ-"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_xgb = xgb_preds(xgb_model,new_data)"
      ],
      "metadata": {
        "id": "PXLKdT9LewM0"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_pred = ann_preds(ann_model,new_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVI4E6wBxVEI",
        "outputId": "a167e2f7-b0be-432c-a76a-47c6ab5412d6"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble Predictions"
      ],
      "metadata": {
        "id": "z6HddIIOxVAv"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame()\n",
        "test_df['XGB_Pred'] = pred_xgb\n",
        "test_df['ANN_Pred'] = ann_pred"
      ],
      "metadata": {
        "id": "KjqtCAN_xU27"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Ensemble_prob'] = (test_df['XGB_Pred'] + test_df['ANN_Pred'])/2"
      ],
      "metadata": {
        "id": "0o0sDTf-yW70"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Ensemble_Pred'] = test_df['Ensemble_prob'].round()"
      ],
      "metadata": {
        "id": "D4ux0BC1yW4X"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Decoding the prediction and mapping to either Select or Reject***"
      ],
      "metadata": {
        "id": "BMU8_g5BzeVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = joblib.load('/content/label_encoder.joblib')"
      ],
      "metadata": {
        "id": "CuCcuRl2zdu_"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Decision'] = le.inverse_transform(test_df['Ensemble_Pred'].astype(int))"
      ],
      "metadata": {
        "id": "POuCbBCbyW1l"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Decision'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "hjxuqmytxT5T",
        "outputId": "95c36db9-ffa3-461e-811f-ed4919c02c73"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decision\n",
              "reject    51\n",
              "select    49\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>reject</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>select</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Decision'] = test_df['Decision']"
      ],
      "metadata": {
        "id": "AR28cU2zxT2i"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() ## For prediction Data added Decision column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "jCjOUMwKxTzS",
        "outputId": "ab080f8d-b739-4eb2-8aa3-054d405d6dcf"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID           Name               Role  \\\n",
              "0  rivash0038    lahar singh  software engineer   \n",
              "1   benjry660  benjamin ryan      data engineer   \n",
              "2  rivash0968    amisha bedi     data scientist   \n",
              "3  rivash0623  kairav mishra    product manager   \n",
              "4   bradgr792  bradley gross    product manager   \n",
              "\n",
              "                                          Transcript  \\\n",
              "0  **lahar singh: software engineer candidate int...   \n",
              "1  interview transcript: data engineer position\\n...   \n",
              "2  **interview transcript: amisha bedi, data scie...   \n",
              "3  **interview transcript: product manager positi...   \n",
              "4  product manager interview transcript\\n\\ninterv...   \n",
              "\n",
              "                                              Resume  \\\n",
              "0  **lahar singh**\\n**software engineer candidate...   \n",
              "1  here's a sample resume for benjamin ryan apply...   \n",
              "2  **candidate profile: amisha bedi**\\n\\n**role:*...   \n",
              "3  **kairav mishra: product manager**\\n\\nas a sea...   \n",
              "4  here's a sample resume for bradley gross apply...   \n",
              "\n",
              "                                 Reason for decision  \\\n",
              "0  expected_experience : 9+ years, domains: e-com...   \n",
              "1                                       cultural fit   \n",
              "2  expected_experience : 6-8 years, domains: heal...   \n",
              "3  expected_experience : 6-8 years, domains: tech...   \n",
              "4                                       cultural fit   \n",
              "\n",
              "                                     Job Description Decision  \n",
              "0  communicated ideas clearly and effectively., h...   select  \n",
              "1  we are looking for a skilled data engineer wit...   reject  \n",
              "2  lacked key technical skills for the role., nee...   reject  \n",
              "3  had impressive experience and qualifications.,...   select  \n",
              "4  we are looking for a skilled product manager w...   select  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81ae449e-5cd0-422b-8b10-dad9558a4e9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Role</th>\n",
              "      <th>Transcript</th>\n",
              "      <th>Resume</th>\n",
              "      <th>Reason for decision</th>\n",
              "      <th>Job Description</th>\n",
              "      <th>Decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rivash0038</td>\n",
              "      <td>lahar singh</td>\n",
              "      <td>software engineer</td>\n",
              "      <td>**lahar singh: software engineer candidate int...</td>\n",
              "      <td>**lahar singh**\\n**software engineer candidate...</td>\n",
              "      <td>expected_experience : 9+ years, domains: e-com...</td>\n",
              "      <td>communicated ideas clearly and effectively., h...</td>\n",
              "      <td>select</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>benjry660</td>\n",
              "      <td>benjamin ryan</td>\n",
              "      <td>data engineer</td>\n",
              "      <td>interview transcript: data engineer position\\n...</td>\n",
              "      <td>here's a sample resume for benjamin ryan apply...</td>\n",
              "      <td>cultural fit</td>\n",
              "      <td>we are looking for a skilled data engineer wit...</td>\n",
              "      <td>reject</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rivash0968</td>\n",
              "      <td>amisha bedi</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>**interview transcript: amisha bedi, data scie...</td>\n",
              "      <td>**candidate profile: amisha bedi**\\n\\n**role:*...</td>\n",
              "      <td>expected_experience : 6-8 years, domains: heal...</td>\n",
              "      <td>lacked key technical skills for the role., nee...</td>\n",
              "      <td>reject</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rivash0623</td>\n",
              "      <td>kairav mishra</td>\n",
              "      <td>product manager</td>\n",
              "      <td>**interview transcript: product manager positi...</td>\n",
              "      <td>**kairav mishra: product manager**\\n\\nas a sea...</td>\n",
              "      <td>expected_experience : 6-8 years, domains: tech...</td>\n",
              "      <td>had impressive experience and qualifications.,...</td>\n",
              "      <td>select</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bradgr792</td>\n",
              "      <td>bradley gross</td>\n",
              "      <td>product manager</td>\n",
              "      <td>product manager interview transcript\\n\\ninterv...</td>\n",
              "      <td>here's a sample resume for bradley gross apply...</td>\n",
              "      <td>cultural fit</td>\n",
              "      <td>we are looking for a skilled product manager w...</td>\n",
              "      <td>select</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81ae449e-5cd0-422b-8b10-dad9558a4e9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81ae449e-5cd0-422b-8b10-dad9558a4e9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81ae449e-5cd0-422b-8b10-dad9558a4e9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-126e8c69-3f49-4a57-b28d-5a727ac6b11e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-126e8c69-3f49-4a57-b28d-5a727ac6b11e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-126e8c69-3f49-4a57-b28d-5a727ac6b11e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"rivash0185\",\n          \"anangu98\",\n          \"natabe717\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"lisa freeman\",\n          \"thomas olson\",\n          \"mythily chawla\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"software engineer\",\n          \"data engineer\",\n          \"ui designer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"**interview transcript**\\n\\n**interviewer:** rohan gupta, senior software engineer\\n**candidate:** manav chopra, software engineer candidate\\n**position:** software engineer\\n**date:** march 10, 2023\\n**time:** 10:00 am\\n\\n**rohan gupta:** good morning, manav. thank you for coming in today. can you start by telling me a little bit about yourself and why you're interested in this software engineer role?\\n\\n**manav chopra:** hi rohan. i have about 7 years of experience in software development, primarily in java and python. i've worked on various projects, including e-commerce and banking platforms. i'm excited about this role because i'm looking to transition into a more challenging position where i can utilize my skills to contribute to a successful team.\\n\\n**rohan gupta:** that's great. can you walk me through your experience with software development? specifically, what languages and technologies have you worked with?\\n\\n**manav chopra:** i've primarily worked with java and python. i've also dabbled in javascript and c++. however, i've never worked extensively with the latest technologies in the industry, such as react, angular, or vue.js.\\n\\n**rohan gupta:** i see. can you give me an example of a project you've worked on where you applied algorithms and data structures to solve a complex problem?\\n\\n**manav chopra:** um... i think i can give you an example of a project i worked on where i used a basic sorting algorithm. we were trying to optimize the performance of our application, and i used a simple sorting algorithm to improve the efficiency of our data processing. however, i don't recall the specific details of the project, and i'm not sure if i can explain the algorithm in depth.\\n\\n**rohan gupta:** i see. let's talk about version control. can you tell me about your experience with git?\\n\\n**manav chopra:** i've used git for source control. i can create a new branch, make changes, and commit them. however, i've never worked on a large-scale project with multiple contributors, and i'm not sure how to resolve conflicts or optimize our team's workflow.\\n\\n**rohan gupta:** database management is a critical aspect of our work. can you walk me through your experience with database design and management?\\n\\n**manav chopra:** i've worked with mysql and postgresql. i can create basic database schema and queries. however, i'm not familiar with more advanced concepts, such as indexing, caching, or query optimization.\\n\\n**rohan gupta:** web development is a significant part of our work. can you tell me about your experience with web development frameworks and technologies?\\n\\n**manav chopra:** i've worked with spring and django. i can create a basic web application using these frameworks. however, i'm not familiar with more modern web development technologies, such as microservices or serverless architecture.\\n\\n**rohan gupta:** i understand you have experience in the e-commerce domain. can you tell me about a specific project you worked on in e-commerce, and what your role was in that project?\\n\\n**manav chopra:** i worked on an e-commerce platform as a junior developer. i was responsible for implementing basic features, such as product listing and payment processing. however, i don't recall the specifics of the project, and i'm not sure if i can discuss it in detail.\\n\\n**rohan gupta:** i see. based on our conversation, i think there are a few areas where you could improve. specifically, you could work on developing a stronger understanding of algorithms and data structures, as well as improving your problem-solving skills. additionally, you could gain more experience in the required domains, such as banking and education. can you tell me how you plan to address these areas in the next 6-12 months?\\n\\n**manav chopra:** yes, i can see where i need to improve. i plan to take online courses to improve my understanding of algorithms and data structures. i'll also try to work on more challenging projects to improve my problem-solving skills. additionally, i'll try to gain more experience in the required domains by taking on freelance work or contributing to open-source projects.\\n\\n**rohan gupta:** thank you, manav. lastly, can you tell me why you're interested in this role, and what you think you can bring to our team?\\n\\n**manav chopra:** i'm interested in this role because i'm looking to transition into a more challenging position where i can utilize my skills to contribute to a successful team. i think i can bring a strong work ethic and a willingness to learn to our team.\\n\\n**rohan gupta:** thank you, manav. do you have any questions for me?\\n\\n**manav chopra:** yes, i do. can you tell me more about the team i would be working with, and what the typical workflow is like?\\n\\n**rohan gupta:** absolutely. our team is a collaborative and dynamic group of experienced engineers. we work on a variety of projects, and our workflow is centered around agile methodologies. we prioritize communication and collaboration, and we're always looking for ways to improve our processes and deliver high-quality results.\\n\\n**rohan gupta:** thank you, manav, for taking the time to speak with me today. do you have any final thoughts or questions?\\n\\n**manav chopra:** no, i don't think so. thank you again for the opportunity to interview.\\n\\n**rohan gupta:** thank you, manav. we'll be in touch soon to let you know the next steps.\",\n          \"here's a realistic interview transcript for a ui engineer position, with ananya gupta as the candidate:\\n\\ninterviewer: hi ananya, thanks for coming in today. can you start by telling me a little bit about your background and how you think your skills align with this ui engineer role?\\n\\nananya: absolutely. i have about 3 years of experience in ui development, with a focus on front-end technologies like html, css, and javascript. i've worked on several projects, including a few web applications and a mobile app. i'm confident in my ability to design and implement visually appealing and user-friendly interfaces.\\n\\ninterviewer: that's great. can you walk me through your process for designing a ui component, let's say a button? how do you decide on the layout, color scheme, and other visual elements?\\n\\nananya: sure. i start by researching the project's brand guidelines and identifying the key design principles. i then sketch out some rough ideas using a tool like sketch or figma. from there, i refine the design, considering factors like accessibility, usability, and responsiveness. i also make sure to test the design with real users to ensure it meets their needs.\\n\\ninterviewer: excellent approach. now, let's talk about implementation. can you walk me through how you would build a button component using a framework like react?\\n\\nananya: (nervously chuckles) okay, so... i'd start by creating a new react component, let's call it `button.js`. i'd then define the component's props, including the button's text, color, and size. i'd use css-in-js to style the component, and i'd make sure to handle accessibility features like keyboard navigation and aria attributes.\\n\\ninterviewer: that's a good start. however, i've noticed that your implementation doesn't account for different button states, like hover or focus. how would you handle that?\\n\\nananya: (pauses) ah, good point. i'd need to add more styles to handle those states. i'd use css classes to apply different styles based on the component's state. (pauses again) wait, how do i... um... manage all those styles? (laughs nervously)\\n\\ninterviewer: (smiling) don't worry, it's a common challenge. one approach is to use a css preprocessor like sass or less, which can help you organize and manage your styles more efficiently.\\n\\ninterviewer: let's move on to version control. can you tell me about your experience with git and how you use it in your daily work?\\n\\nananya: (hesitates) okay, so... i've used git before, but i'm not super familiar with all the advanced features. i mainly use the command line to commit and push changes. i'm not really sure how to use branches, or how to merge conflicts... (trails off)\\n\\ninterviewer: that's okay, we can discuss those topics in more detail. however, i'm concerned that you may not be using version control effectively in your current projects.\\n\\ninterviewer: finally, let's talk about testing. how do you ensure that your ui components are thoroughly tested?\\n\\nananya: (confidently) i use a combination of unit tests and integration tests to verify that my components behave as expected. i also use tools like jest and enzyme to write and run my tests.\\n\\ninterviewer: great approach. can you walk me through a specific example of a test you wrote for a ui component?\\n\\nananya: (excitedly) yes! let me tell you about this one test i wrote for a dropdown menu component. i used jest to write a unit test that verifies the component's props are passed correctly, and that it renders the correct number of options. i also used enzyme to write an integration test that verifies the component's behavior when interacted with by a user.\\n\\ninterviewer: that's excellent! it's clear that you have a good understanding of testing principles and tools.\\n\\nsummary: ananya demonstrates a good grasp of ui design principles, front-end technologies like react, and testing frameworks like jest and enzyme. however, she struggles with version control concepts and practices, particularly the use of git. while she can implement ui components and write tests, she may benefit from additional training or guidance on these areas.\\n\\nrating: 7/10 (ananya's strengths in ui design, front-end development, and testing outweigh her weaknesses in version control, but she needs improvement in these areas.)\",\n          \"product manager interview transcript\\n\\ninterviewer: rachel lee, director of product\\ncandidate: natalie bell, product manager candidate\\ndate: march 10, 2023\\ntime: 2:00 pm\\n\\nrachel lee: natalie, thank you for coming in today. can you start by telling me a little bit about your background and why you're interested in this product manager role?\\n\\nnatalie bell: absolutely. i have about 5 years of experience in product management, and i'm excited about the opportunity to join your team because of the company's mission and values align with my own. i've done some research on the product and am impressed with the direction it's heading.\\n\\nrachel lee: great, thank you for sharing that. let's dive into the skills required for this role. can you walk me through your process when analyzing customer data to inform product decisions?\\n\\nnatalie bell: uh, well... i think the process is... (pauses) we collect data, and then we... (trails off) i'm not sure i can give a specific example of how i've used data analysis to drive product decisions. i'm more of a creative person, and i rely on my instincts.\\n\\nrachel lee: i see. data analysis is a critical skill for this role. can you give me an example of a time when you had to present complex data insights to a non-technical stakeholder, such as a customer or executive?\\n\\nnatalie bell: honestly, i don't think i've had to do that often. i'm not sure i'm the best at explaining technical concepts in a way that's easy for others to understand. i try to focus on the big picture and leave the details to others.\\n\\nrachel lee: i appreciate your honesty. as a product manager, you'll need to effectively communicate with various stakeholders, including technical and non-technical team members. let's move on to a scenario-based question. imagine you're tasked with launching a new feature, but the development team is running behind schedule. how would you handle this situation?\\n\\nnatalie bell: i would... (pauses) i think i would try to find a way to make it work, even if it means sacrificing some of the original vision. i'm not sure i'm great at prioritizing features or managing trade-offs.\\n\\nrachel lee: thank you for sharing your thoughts, natalie. based on our conversation today, i have some concerns about your ability to perform the skills required for this role, particularly data analysis and stakeholder communication. do you have any questions for me?\\n\\nnatalie bell: yeah, actually. can you tell me more about the team i'd be working with, and what the typical workflow looks like?\\n\\nrachel lee: absolutely. our team is collaborative and cross-functional. we work closely with engineering, design, and marketing to deliver high-quality products. i'd be happy to provide more information on the team and workflow.\\n\\nrachel lee: thank you, natalie, for taking the time to speak with me today. we'll be in touch soon to let you know about next steps.\\n\\nnatalie bell: thank you, rachel. i appreciate the opportunity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resume\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"**candidate profile: manav chopra**\\n\\n**interview details**\\n\\n* job title: software engineer\\n* date: [insert date]\\n* interviewer: [insert name]\\n\\n**summary**\\n\\nmanav chopra demonstrated enthusiasm and eagerness to learn during the interview, but there were several areas where his skills and experience fell short of the job requirements. while he showed potential, there are concerns regarding his proficiency in essential software engineering skills.\\n\\n**key areas for improvement**\\n\\n1. **software development**: manav lacks hands-on experience in software development, which is a critical aspect of the software engineer role. he struggled to provide specific examples of projects or code he has developed, and his understanding of software development life cycles was limited.\\n2. **algorithms and data structures**: manav's knowledge of algorithms and data structures was limited, and he was unable to demonstrate problem-solving skills or provide examples of common data structures.\\n3. **version control (git)**: although familiar with the concept of version control, manav did not demonstrate hands-on experience with git, and his understanding of branching strategies and conflict resolution was limited.\\n4. **database management**: manav's experience with database management systems was scarce, and he was unfamiliar with common database concepts, such as normalization and indexing.\\n5. **web development**: manav did not have any experience with web development, and his understanding of web technologies, such as html, css, and javascript, was limited.\\n6. **programming languages**: manav's proficiency in object-oriented programming languages (e.g., java, c++, python) was inconsistent, and he struggled to demonstrate his understanding of language-specific concepts.\\n\\n**concerns raised during the interview**\\n\\n* manav had difficulty with certain tasks, such as writing clean, efficient code, and solving algorithmic problems.\\n* he was unfamiliar with specific tools and technologies, such as git, which raised concerns about his ability to work effectively in a collaborative environment.\\n* manav's lack of experience with web development and database management systems made it challenging for him to understand the importance of these skills in software engineering.\\n\\n**potential for growth**\\n\\ndespite the gaps in his skills, manav demonstrated a willingness to learn and asked insightful questions during the interview. with further training and exposure to software engineering concepts, algorithms, and technologies, he may be able to bridge the gaps and develop the necessary skills for the role.\\n\\n**recommendations**\\n\\n* provide manav with additional training and resources to improve his understanding of software development, algorithms, and data structures.\\n* encourage him to work on personal projects to gain hands-on experience with version control, database management, and web development.\\n* pair him with a mentor or senior engineer to guide him in his learning journey and ensure he is equipped with the necessary skills for the role.\\n\\n**conclusion**\\n\\nmanav chopra has potential, but his current skills and experience do not align with the requirements of the software engineer role. with targeted training and support, he may be able to develop the necessary skills to succeed in this position.\",\n          \"ananya gupta\\nui engineer\\n\\ncontact information:\\n\\n* email: [ananyagupta@email.com](mailto:ananyagupta@email.com)\\n* phone: 123-456-7890\\n* linkedin: linkedin.com/in/ananyagupta\\n\\nsummary:\\nhighly motivated and detail-oriented ui engineer with 3+ years of experience in designing and developing responsive, accessible, and high-performance web applications using react, html, css, and javascript. proficient in ui/ux design principles, version control, and frontend testing. committed to delivering exceptional user experiences and ensuring seamless user interactions.\\n\\ntechnical skills:\\n\\n* frontend frameworks: react, webpack\\n* programming languages: html, css, javascript\\n* ui/ux design tools: sketch, figma\\n* responsive design: mobile-first design, media queries\\n* web accessibility: wcag 2.1, section 508\\n* version control: git, github\\n* frontend testing: jest, enzyme\\n* web performance: lighthouse, webpagetest\\n\\nprofessional experience:\\n\\nui engineer, abc corporation (2020-present)\\n\\n* designed and developed responsive, accessible, and high-performance web applications using react, html, css, and javascript\\n* collaborated with cross-functional teams to ensure seamless user interactions and exceptional user experiences\\n* implemented ui/ux design principles to enhance user engagement and conversion rates\\n* conducted frontend testing using jest and enzyme to ensure bug-free and efficient code\\n* optimized web performance using lighthouse and webpagetest to improve page load times and user experience\\n\\nfrontend developer, def startups (2018-2020)\\n\\n* developed responsive, accessible, and high-performance web applications using html, css, and javascript\\n* collaborated with designers to implement ui/ux design principles and ensure seamless user interactions\\n* implemented version control using git and github to manage code changes and collaborate with team members\\n* conducted frontend testing to ensure bug-free and efficient code\\n\\neducation:\\n\\n* bachelor of science in computer science, xyz university (2015-2019)\\n* certified frontend developer, codecademy (2019)\\n\\nachievements:\\n\\n* winner, abc corporation's hackathon (2020) - developed a responsive, accessible, and high-performance web application using react, html, css, and javascript\\n* featured speaker, def startups' tech conference (2019) - presented on \\\"best practices for responsive design and web accessibility\\\"\\n* published article, codecademy's blog (2019) - wrote on \\\"frontend testing using jest and enzyme\\\"\\n\\ncertifications:\\n\\n* certified frontend developer, codecademy (2019)\\n* certified web accessibility specialist, web accessibility initiative (2018)\\n\\nreferences:\\navailable upon request.\",\n          \"here's a sample resume for natalie bell applying for a product manager role:\\n\\nnatalie bell\\ncontact information:\\n\\n* phone: (555) 123-4567\\n* email: [natalie.bell@email.com](mailto:natalie.bell@email.com)\\n* linkedin: linkedin.com/in/nataliebell\\n* location: san francisco, ca\\n\\nsummary:\\nresults-driven product manager with 5+ years of experience in leading product development teams and driving business growth through data-driven decision making. skilled in creating and executing product roadmaps, leveraging agile methodologies, and conducting market research to inform product strategy.\\n\\nprofessional experience:\\n\\nsenior product manager, xyz corporation (2018-present)\\n\\n* develop and execute product roadmaps that drive business growth and revenue expansion\\n* lead cross-functional product teams to design, develop, and launch new products and features\\n* conduct market research and competitive analysis to inform product strategy and prioritize features\\n* collaborate with engineering, design, and sales teams to ensure product meets business and customer needs\\n* analyze product performance metrics to identify areas for improvement and optimize product roadmap\\n\\nproduct manager, abc startups (2015-2018)\\n\\n* created and executed product roadmaps that drove product adoption and customer engagement\\n* conducted market research and user testing to inform product design and feature prioritization\\n* collaborated with engineering and design teams to launch new products and features\\n* analyzed product performance metrics to identify areas for improvement and optimize product roadmap\\n\\neducation:\\n\\n* bachelor's degree in business administration, stanford university (2010-2014)\\n\\nskills:\\n\\n* product management and leadership\\n* roadmapping and product planning\\n* agile methodologies and scrum framework\\n* market research and competitive analysis\\n* data analysis and performance metrics\\n* cross-functional team management\\n* collaboration and communication\\n\\ncertifications/awards:\\n\\n* certified product manager (cpm) designation\\n* winner of the 2020 product management award for excellence in product strategy\\n\\nreferences:\\navailable upon request.\\n\\ni hope this sample resume helps! let me know if you have any questions or if you'd like me to revise anything.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reason for decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"expected_experience : 6-8 years, domains: logistics, finance, healthcare\",\n          \"expected_experience : 0-2 years, domains: marketing, finance, healthcare\",\n          \"expected_experience : 9+ years, domains: e-commerce, banking, education\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"we are looking for a skilled product manager with expertise in leadership, market research, stakeholder communication, roadmaps.\",\n          \"needed improvement in problem-solving skills., had insufficient experience for the position.\",\n          \"we are looking for a skilled data scientist with expertise in statistics, python, deep learning, sql.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"reject\",\n          \"select\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    }
  ]
}